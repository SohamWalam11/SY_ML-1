{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Mr0ZAZozGZYV",
        "1nRl8-f_Gy1C",
        "JI63K0J2Ha3D"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Q1"
      ],
      "metadata": {
        "id": "Mr0ZAZozGZYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression from Scratch**"
      ],
      "metadata": {
        "id": "LKCg8YYqGeeb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVOlaRQiF7Jx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(42)\n",
        "X, y = make_classification(n_samples=1000, n_features=5, n_classes=2, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "class LogisticRegressionScratch:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.m, self.n = X.shape\n",
        "        self.weights = np.zeros(self.n)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_pred = self.sigmoid(linear_model)\n",
        "\n",
        "            # Compute gradients\n",
        "            dw = (1 / self.m) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / self.m) * np.sum(y_pred - y)\n",
        "\n",
        "            # Update weights and bias\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_pred = self.sigmoid(linear_model)\n",
        "        return np.where(y_pred >= 0.5, 1, 0)\n",
        "\n",
        "# Train and evaluate\n",
        "lr_scratch = LogisticRegressionScratch(learning_rate=0.01, epochs=1000)\n",
        "lr_scratch.fit(X_train, y_train)\n",
        "y_pred_scratch = lr_scratch.predict(X_test)\n",
        "\n",
        "f1_scratch = f1_score(y_test, y_pred_scratch)\n",
        "print(\"F1 Score (Logistic Regression from Scratch):\", f1_scratch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression using Library**"
      ],
      "metadata": {
        "id": "xKvI19XyGrFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train and evaluate using Scikit-learn\n",
        "lr_sklearn = LogisticRegression()\n",
        "lr_sklearn.fit(X_train, y_train)\n",
        "y_pred_sklearn = lr_sklearn.predict(X_test)\n",
        "\n",
        "f1_sklearn = f1_score(y_test, y_pred_sklearn)\n",
        "print(\"F1 Score (Logistic Regression using Scikit-learn):\", f1_sklearn)\n"
      ],
      "metadata": {
        "id": "n4j1rBZBGm7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2"
      ],
      "metadata": {
        "id": "1nRl8-f_Gy1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform multimodal classification on dataset using python library**"
      ],
      "metadata": {
        "id": "yJaB69fFHR24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"Iris.csv\"  # Update with correct file path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop the 'Id' column\n",
        "df = df.drop(columns=[\"Id\"])\n",
        "\n",
        "# Encode the target variable (Species)\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Species\"] = label_encoder.fit_transform(df[\"Species\"])  # Convert categorical labels to numbers\n",
        "\n",
        "# Split the dataset\n",
        "X = df.drop(columns=[\"Species\"])\n",
        "y = df[\"Species\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN-oSlPHGxVp",
        "outputId": "894ccf56-e9a9-41be-9368-41f6abbd1308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9333333333333333\n",
            "F1 Score: 0.9333333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3"
      ],
      "metadata": {
        "id": "JI63K0J2Ha3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the results of logistic regression model with and without regularization**"
      ],
      "metadata": {
        "id": "3G2u1XkdH0Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Train Logistic Regression WITHOUT regularization (C is very high to disable regularization)\n",
        "lr_no_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=1e6)\n",
        "lr_no_reg.fit(X_train, y_train)\n",
        "y_pred_no_reg = lr_no_reg.predict(X_test)\n",
        "\n",
        "# Train Logistic Regression WITH regularization (default L2, C=1.0)\n",
        "lr_with_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=1.0)\n",
        "lr_with_reg.fit(X_train, y_train)\n",
        "y_pred_with_reg = lr_with_reg.predict(X_test)\n",
        "\n",
        "# Evaluate both models\n",
        "accuracy_no_reg = accuracy_score(y_test, y_pred_no_reg)\n",
        "f1_no_reg = f1_score(y_test, y_pred_no_reg, average=\"weighted\")\n",
        "\n",
        "accuracy_with_reg = accuracy_score(y_test, y_pred_with_reg)\n",
        "f1_with_reg = f1_score(y_test, y_pred_with_reg, average=\"weighted\")\n",
        "\n",
        "# Print results\n",
        "print(\"Without Regularization -> Accuracy:\", accuracy_no_reg, \"F1 Score:\", f1_no_reg)\n",
        "print(\"With Regularization -> Accuracy:\", accuracy_with_reg, \"F1 Score:\", f1_with_reg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w71G6KTZHcec",
        "outputId": "99fcdbe1-cf1b-4a35-9d4b-91759a713f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Regularization -> Accuracy: 1.0 F1 Score: 1.0\n",
            "With Regularization -> Accuracy: 0.9333333333333333 F1 Score: 0.9333333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}